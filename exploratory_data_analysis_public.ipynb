{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5cb8441",
   "metadata": {},
   "source": [
    "# Exploratory Data Anaysis\n",
    "## Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6afff0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime\n",
    "import requests.exceptions\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1919511c",
   "metadata": {},
   "source": [
    "## Load Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a35e8142",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_scores = pd.read_csv('data\\clean\\cleaned_combined_wine_data.csv')\n",
    "weather_data = pd.read_csv('data\\clean\\combined_weather_data_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d540339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wine Name</th>\n",
       "      <th>Region 1</th>\n",
       "      <th>Region 2</th>\n",
       "      <th>Region 3</th>\n",
       "      <th>Country</th>\n",
       "      <th>Score</th>\n",
       "      <th>Price</th>\n",
       "      <th>Winery</th>\n",
       "      <th>Variety</th>\n",
       "      <th>Vintage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Calem 1961 Colheita Tawny Port (Port)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Port</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>95</td>\n",
       "      <td>320.0</td>\n",
       "      <td>Calem</td>\n",
       "      <td>Port Blend</td>\n",
       "      <td>1961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Calem 1961 Colheita Tawny  (Port)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Port</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>95</td>\n",
       "      <td>320.0</td>\n",
       "      <td>Calem</td>\n",
       "      <td>Port</td>\n",
       "      <td>1961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Warre's 1961 Reserve Tawny Port (Port)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Port</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>89</td>\n",
       "      <td>111.0</td>\n",
       "      <td>Warre's</td>\n",
       "      <td>Port Blend</td>\n",
       "      <td>1961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wiese &amp; Krohn 1961 Colheita Port (Port)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Port</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>92</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Wiese &amp; Krohn</td>\n",
       "      <td>Port Blend</td>\n",
       "      <td>1961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cossart Gordon 1962 Bual (Madeira)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Madeira</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>96</td>\n",
       "      <td>355.0</td>\n",
       "      <td>Cossart Gordon</td>\n",
       "      <td>Madeira</td>\n",
       "      <td>1962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Wine Name Region 1 Region 2 Region 3  \\\n",
       "0    Calem 1961 Colheita Tawny Port (Port)      NaN     Port      NaN   \n",
       "1        Calem 1961 Colheita Tawny  (Port)      NaN     Port      NaN   \n",
       "2   Warre's 1961 Reserve Tawny Port (Port)      NaN     Port      NaN   \n",
       "3  Wiese & Krohn 1961 Colheita Port (Port)      NaN     Port      NaN   \n",
       "4       Cossart Gordon 1962 Bual (Madeira)      NaN  Madeira      NaN   \n",
       "\n",
       "    Country  Score  Price          Winery     Variety  Vintage  \n",
       "0  Portugal     95  320.0           Calem  Port Blend     1961  \n",
       "1  Portugal     95  320.0           Calem        Port     1961  \n",
       "2  Portugal     89  111.0         Warre's  Port Blend     1961  \n",
       "3  Portugal     92  200.0   Wiese & Krohn  Port Blend     1961  \n",
       "4  Portugal     96  355.0  Cossart Gordon     Madeira     1962  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity Check\n",
    "wine_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37f08474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station ID</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Year</th>\n",
       "      <th>Jan</th>\n",
       "      <th>Feb</th>\n",
       "      <th>Mar</th>\n",
       "      <th>Apr</th>\n",
       "      <th>May</th>\n",
       "      <th>Jun</th>\n",
       "      <th>Jul</th>\n",
       "      <th>Aug</th>\n",
       "      <th>Sep</th>\n",
       "      <th>Oct</th>\n",
       "      <th>Nov</th>\n",
       "      <th>Dec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5046</td>\n",
       "      <td>INDONESIA</td>\n",
       "      <td>KIJANG TANJUNG PINANG</td>\n",
       "      <td>4</td>\n",
       "      <td>1993</td>\n",
       "      <td>25.6</td>\n",
       "      <td>25.6</td>\n",
       "      <td>25.7</td>\n",
       "      <td>26.0</td>\n",
       "      <td>25.9</td>\n",
       "      <td>26.8</td>\n",
       "      <td>25.8</td>\n",
       "      <td>26.3</td>\n",
       "      <td>25.8</td>\n",
       "      <td>25.4</td>\n",
       "      <td>25.4</td>\n",
       "      <td>25.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5046</td>\n",
       "      <td>INDONESIA</td>\n",
       "      <td>KIJANG TANJUNG PINANG</td>\n",
       "      <td>4</td>\n",
       "      <td>1995</td>\n",
       "      <td>26.0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>25.9</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>26.6</td>\n",
       "      <td>26.3</td>\n",
       "      <td>26.2</td>\n",
       "      <td>26.7</td>\n",
       "      <td>26.1</td>\n",
       "      <td>25.9</td>\n",
       "      <td>25.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5046</td>\n",
       "      <td>INDONESIA</td>\n",
       "      <td>KIJANG TANJUNG PINANG</td>\n",
       "      <td>5</td>\n",
       "      <td>1993</td>\n",
       "      <td>246.6</td>\n",
       "      <td>61.9</td>\n",
       "      <td>285.8</td>\n",
       "      <td>324.2</td>\n",
       "      <td>424.1</td>\n",
       "      <td>169.6</td>\n",
       "      <td>261.7</td>\n",
       "      <td>157.9</td>\n",
       "      <td>240.3</td>\n",
       "      <td>398.5</td>\n",
       "      <td>473.6</td>\n",
       "      <td>683.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5046</td>\n",
       "      <td>INDONESIA</td>\n",
       "      <td>KIJANG TANJUNG PINANG</td>\n",
       "      <td>5</td>\n",
       "      <td>1995</td>\n",
       "      <td>388.0</td>\n",
       "      <td>325.1</td>\n",
       "      <td>190.7</td>\n",
       "      <td>357.9</td>\n",
       "      <td>299.5</td>\n",
       "      <td>334.3</td>\n",
       "      <td>250.9</td>\n",
       "      <td>213.4</td>\n",
       "      <td>265.6</td>\n",
       "      <td>496.3</td>\n",
       "      <td>630.8</td>\n",
       "      <td>277.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5046</td>\n",
       "      <td>INDONESIA</td>\n",
       "      <td>KIJANG TANJUNG PINANG</td>\n",
       "      <td>6</td>\n",
       "      <td>1993</td>\n",
       "      <td>29.6</td>\n",
       "      <td>30.7</td>\n",
       "      <td>30.6</td>\n",
       "      <td>31.3</td>\n",
       "      <td>29.8</td>\n",
       "      <td>31.2</td>\n",
       "      <td>30.7</td>\n",
       "      <td>31.3</td>\n",
       "      <td>30.7</td>\n",
       "      <td>30.3</td>\n",
       "      <td>29.9</td>\n",
       "      <td>29.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Station ID    Country                   City  Data Type  Year    Jan  \\\n",
       "0        5046  INDONESIA  KIJANG TANJUNG PINANG          4  1993   25.6   \n",
       "1        5046  INDONESIA  KIJANG TANJUNG PINANG          4  1995   26.0   \n",
       "2        5046  INDONESIA  KIJANG TANJUNG PINANG          5  1993  246.6   \n",
       "3        5046  INDONESIA  KIJANG TANJUNG PINANG          5  1995  388.0   \n",
       "4        5046  INDONESIA  KIJANG TANJUNG PINANG          6  1993   29.6   \n",
       "\n",
       "     Feb    Mar    Apr    May    Jun    Jul    Aug    Sep    Oct    Nov    Dec  \n",
       "0   25.6   25.7   26.0   25.9   26.8   25.8   26.3   25.8   25.4   25.4   25.9  \n",
       "1   25.6   25.9   26.0   26.6   26.6   26.3   26.2   26.7   26.1   25.9   25.6  \n",
       "2   61.9  285.8  324.2  424.1  169.6  261.7  157.9  240.3  398.5  473.6  683.9  \n",
       "3  325.1  190.7  357.9  299.5  334.3  250.9  213.4  265.6  496.3  630.8  277.1  \n",
       "4   30.7   30.6   31.3   29.8   31.2   30.7   31.3   30.7   30.3   29.9   29.9  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590afd4d",
   "metadata": {},
   "source": [
    "## Working Dataframes\n",
    "We need to create some temporary working dataframes for us to do preliminary data exploration. First lets reduce the amount of weather data we have by just grabbing the data from countries and years that we have wines for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1b81c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station ID</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Year</th>\n",
       "      <th>Jan</th>\n",
       "      <th>Feb</th>\n",
       "      <th>Mar</th>\n",
       "      <th>Apr</th>\n",
       "      <th>May</th>\n",
       "      <th>Jun</th>\n",
       "      <th>Jul</th>\n",
       "      <th>Aug</th>\n",
       "      <th>Sep</th>\n",
       "      <th>Oct</th>\n",
       "      <th>Nov</th>\n",
       "      <th>Dec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>SCONE SOIL CONS          0</td>\n",
       "      <td>4</td>\n",
       "      <td>1985</td>\n",
       "      <td>24.6</td>\n",
       "      <td>22.4</td>\n",
       "      <td>21.5</td>\n",
       "      <td>17.7</td>\n",
       "      <td>14.2</td>\n",
       "      <td>10.2</td>\n",
       "      <td>10.6</td>\n",
       "      <td>11.3</td>\n",
       "      <td>13.2</td>\n",
       "      <td>17.2</td>\n",
       "      <td>19.1</td>\n",
       "      <td>22.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>SCONE SOIL CONS          0</td>\n",
       "      <td>4</td>\n",
       "      <td>1987</td>\n",
       "      <td>25.7</td>\n",
       "      <td>24.7</td>\n",
       "      <td>19.6</td>\n",
       "      <td>17.9</td>\n",
       "      <td>14.2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>14.8</td>\n",
       "      <td>17.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>SCONE SOIL CONS          0</td>\n",
       "      <td>5</td>\n",
       "      <td>1985</td>\n",
       "      <td>4.6</td>\n",
       "      <td>88.8</td>\n",
       "      <td>48.6</td>\n",
       "      <td>53.8</td>\n",
       "      <td>36.2</td>\n",
       "      <td>55.2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>45.2</td>\n",
       "      <td>76.4</td>\n",
       "      <td>143.2</td>\n",
       "      <td>33.4</td>\n",
       "      <td>121.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>SCONE SOIL CONS          0</td>\n",
       "      <td>5</td>\n",
       "      <td>1987</td>\n",
       "      <td>90.6</td>\n",
       "      <td>4.8</td>\n",
       "      <td>82.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>73.4</td>\n",
       "      <td>20.8</td>\n",
       "      <td>9.8</td>\n",
       "      <td>110.2</td>\n",
       "      <td>19.2</td>\n",
       "      <td>42.6</td>\n",
       "      <td>41.0</td>\n",
       "      <td>113.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6600</td>\n",
       "      <td>SWITZERLAND</td>\n",
       "      <td>ST. CHRISCHONA</td>\n",
       "      <td>4</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.8</td>\n",
       "      <td>9.5</td>\n",
       "      <td>11.7</td>\n",
       "      <td>15.7</td>\n",
       "      <td>17.2</td>\n",
       "      <td>17.7</td>\n",
       "      <td>14.4</td>\n",
       "      <td>10.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Station ID      Country                        City  Data Type  Year   Jan  \\\n",
       "0           0    AUSTRALIA  SCONE SOIL CONS          0          4  1985  24.6   \n",
       "1           0    AUSTRALIA  SCONE SOIL CONS          0          4  1987  25.7   \n",
       "2           0    AUSTRALIA  SCONE SOIL CONS          0          5  1985   4.6   \n",
       "3           0    AUSTRALIA  SCONE SOIL CONS          0          5  1987  90.6   \n",
       "4        6600  SWITZERLAND              ST. CHRISCHONA          4  2004   0.9   \n",
       "\n",
       "    Feb   Mar   Apr   May   Jun   Jul    Aug   Sep    Oct   Nov    Dec  \n",
       "0  22.4  21.5  17.7  14.2  10.2  10.6   11.3  13.2   17.2  19.1   22.8  \n",
       "1  24.7  19.6  17.9  14.2  12.0  10.1   13.1  14.8   17.1  20.0   22.6  \n",
       "2  88.8  48.6  53.8  36.2  55.2  17.0   45.2  76.4  143.2  33.4  121.6  \n",
       "3   4.8  82.8   5.0  73.4  20.8   9.8  110.2  19.2   42.6  41.0  113.8  \n",
       "4   2.3   4.8   9.5  11.7  15.7  17.2   17.7  14.4   10.7   4.0    0.2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data_df = pd.read_csv('data\\clean\\cleaned_combined_wine_data.csv')\n",
    "weather_data_df = pd.read_csv('data\\clean\\combined_weather_data_clean.csv')\n",
    "\n",
    "# Rename the 'Vintage' column in wine_data_df to 'Year' for consistency\n",
    "wine_data_df.rename(columns={'Vintage': 'Year'}, inplace=True)\n",
    "\n",
    "# Standardize country names in wine data to uppercase for matching\n",
    "wine_data_df['Country'] = wine_data_df['Country'].str.upper()\n",
    "\n",
    "# Filter the weather data to only include rows that match the Country and Year in the wine data\n",
    "matched_weather_data = weather_data_df[weather_data_df[['Country', 'Year']].apply(tuple, 1).isin(wine_data_df[['Country', 'Year']].apply(tuple, 1))]\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "matched_weather_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the first few rows of the filtered weather data\n",
    "matched_weather_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1fb94e",
   "metadata": {},
   "source": [
    "Now we want to get rid of the Data Type column, so its easier for someone to read all relevant weather data in one dataframe. Atomosphereric pressure isn't relevant for what we are trying to calculate, and not to mention not all locations measure atomosphereric pressure, so we will be getting ride of data type 2 and 3 if it ever pops up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d889164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station ID</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>Year</th>\n",
       "      <th>daily_temp_Jan</th>\n",
       "      <th>daily_temp_Feb</th>\n",
       "      <th>daily_temp_Mar</th>\n",
       "      <th>daily_temp_Apr</th>\n",
       "      <th>daily_temp_May</th>\n",
       "      <th>daily_temp_Jun</th>\n",
       "      <th>...</th>\n",
       "      <th>humidity_Mar</th>\n",
       "      <th>humidity_Apr</th>\n",
       "      <th>humidity_May</th>\n",
       "      <th>humidity_Jun</th>\n",
       "      <th>humidity_Jul</th>\n",
       "      <th>humidity_Aug</th>\n",
       "      <th>humidity_Sep</th>\n",
       "      <th>humidity_Oct</th>\n",
       "      <th>humidity_Nov</th>\n",
       "      <th>humidity_Dec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>SCONE SOIL CONS          0</td>\n",
       "      <td>1985</td>\n",
       "      <td>24.6</td>\n",
       "      <td>22.4</td>\n",
       "      <td>21.5</td>\n",
       "      <td>17.7</td>\n",
       "      <td>14.2</td>\n",
       "      <td>10.2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>SCONE SOIL CONS          0</td>\n",
       "      <td>1987</td>\n",
       "      <td>25.7</td>\n",
       "      <td>24.7</td>\n",
       "      <td>19.6</td>\n",
       "      <td>17.9</td>\n",
       "      <td>14.2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6600</td>\n",
       "      <td>SWITZERLAND</td>\n",
       "      <td>ST. CHRISCHONA</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.8</td>\n",
       "      <td>9.5</td>\n",
       "      <td>11.7</td>\n",
       "      <td>15.7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6601</td>\n",
       "      <td>SWITZERLAND</td>\n",
       "      <td>BASEL / BINNINGEN</td>\n",
       "      <td>2004</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>10.6</td>\n",
       "      <td>13.2</td>\n",
       "      <td>17.7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6601</td>\n",
       "      <td>SWITZERLAND</td>\n",
       "      <td>BASEL / BINNINGEN</td>\n",
       "      <td>2011</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>7.5</td>\n",
       "      <td>13.4</td>\n",
       "      <td>16.6</td>\n",
       "      <td>18.1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Station ID      Country                        City  Year  daily_temp_Jan  \\\n",
       "0           0    AUSTRALIA  SCONE SOIL CONS          0  1985            24.6   \n",
       "1           0    AUSTRALIA  SCONE SOIL CONS          0  1987            25.7   \n",
       "2        6600  SWITZERLAND              ST. CHRISCHONA  2004             0.9   \n",
       "3        6601  SWITZERLAND           BASEL / BINNINGEN  2004             2.3   \n",
       "4        6601  SWITZERLAND           BASEL / BINNINGEN  2011             2.4   \n",
       "\n",
       "   daily_temp_Feb  daily_temp_Mar  daily_temp_Apr  daily_temp_May  \\\n",
       "0            22.4            21.5            17.7            14.2   \n",
       "1            24.7            19.6            17.9            14.2   \n",
       "2             2.3             4.8             9.5            11.7   \n",
       "3             3.0             5.7            10.6            13.2   \n",
       "4             3.9             7.5            13.4            16.6   \n",
       "\n",
       "   daily_temp_Jun  ...  humidity_Mar  humidity_Apr  humidity_May  \\\n",
       "0            10.2  ...           NaN           NaN           NaN   \n",
       "1            12.0  ...           NaN           NaN           NaN   \n",
       "2            15.7  ...           NaN           NaN           NaN   \n",
       "3            17.7  ...           NaN           NaN           NaN   \n",
       "4            18.1  ...           NaN           NaN           NaN   \n",
       "\n",
       "   humidity_Jun  humidity_Jul  humidity_Aug  humidity_Sep  humidity_Oct  \\\n",
       "0           NaN           NaN           NaN           NaN           NaN   \n",
       "1           NaN           NaN           NaN           NaN           NaN   \n",
       "2           NaN           NaN           NaN           NaN           NaN   \n",
       "3           NaN           NaN           NaN           NaN           NaN   \n",
       "4           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "   humidity_Nov  humidity_Dec  \n",
       "0           NaN           NaN  \n",
       "1           NaN           NaN  \n",
       "2           NaN           NaN  \n",
       "3           NaN           NaN  \n",
       "4           NaN           NaN  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to rename columns based on the data type\n",
    "def rename_columns(df, data_type):\n",
    "    prefix = {\n",
    "        4: 'daily_temp',\n",
    "        5: 'precipitation',\n",
    "        6: 'daily_temp_MAX',\n",
    "        7: 'daily_temp_MIN',\n",
    "        8: 'humidity'\n",
    "    }.get(data_type, 'unknown')\n",
    "\n",
    "    month_cols = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    new_month_cols = [f'{prefix}_{month}' for month in month_cols]\n",
    "    rename_dict = dict(zip(month_cols, new_month_cols))\n",
    "    df.rename(columns=rename_dict, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Splitting the DataFrame into separate DataFrames based on Data Type\n",
    "dfs = {}\n",
    "for dtype in [4, 5, 6, 7, 8]:\n",
    "    df = matched_weather_data[matched_weather_data['Data Type'] == dtype].copy()\n",
    "    df = rename_columns(df, dtype)\n",
    "    dfs[dtype] = df\n",
    "\n",
    "# Drop the 'Data Type' column from each DataFrame and rename the month columns\n",
    "for dtype, df in dfs.items():\n",
    "    df = df.drop(columns=['Data Type'])\n",
    "    df = rename_columns(df, dtype)\n",
    "    dfs[dtype] = df\n",
    "    \n",
    "# Merge the DataFrames back together with explicit suffixes for overlapping columns\n",
    "merged_weather_df = reduce(lambda left, right: pd.merge(left, right, on=['Station ID', 'Country', 'City', 'Year'], how='outer', suffixes=('', '_duplicate')), dfs.values())\n",
    "\n",
    "# Remove any columns that were duplicated during the merge\n",
    "merged_weather_df = merged_weather_df[[col for col in merged_weather_df.columns if not col.endswith('_duplicate')]]\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "merged_weather_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Check results\n",
    "merged_weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a51a6a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40321 entries, 0 to 40320\n",
      "Data columns (total 64 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Station ID          40321 non-null  int64  \n",
      " 1   Country             40321 non-null  object \n",
      " 2   City                40321 non-null  object \n",
      " 3   Year                40321 non-null  int64  \n",
      " 4   daily_temp_Jan      39238 non-null  float64\n",
      " 5   daily_temp_Feb      39238 non-null  float64\n",
      " 6   daily_temp_Mar      39238 non-null  float64\n",
      " 7   daily_temp_Apr      39238 non-null  float64\n",
      " 8   daily_temp_May      39238 non-null  float64\n",
      " 9   daily_temp_Jun      39238 non-null  float64\n",
      " 10  daily_temp_Jul      39238 non-null  float64\n",
      " 11  daily_temp_Aug      39238 non-null  float64\n",
      " 12  daily_temp_Sep      39238 non-null  float64\n",
      " 13  daily_temp_Oct      39238 non-null  float64\n",
      " 14  daily_temp_Nov      39238 non-null  float64\n",
      " 15  daily_temp_Dec      39238 non-null  float64\n",
      " 16  precipitation_Jan   38465 non-null  float64\n",
      " 17  precipitation_Feb   38465 non-null  float64\n",
      " 18  precipitation_Mar   38465 non-null  float64\n",
      " 19  precipitation_Apr   38465 non-null  float64\n",
      " 20  precipitation_May   38465 non-null  float64\n",
      " 21  precipitation_Jun   38465 non-null  float64\n",
      " 22  precipitation_Jul   38465 non-null  float64\n",
      " 23  precipitation_Aug   38465 non-null  float64\n",
      " 24  precipitation_Sep   38465 non-null  float64\n",
      " 25  precipitation_Oct   38465 non-null  float64\n",
      " 26  precipitation_Nov   38465 non-null  float64\n",
      " 27  precipitation_Dec   38465 non-null  float64\n",
      " 28  daily_temp_MAX_Jan  38661 non-null  float64\n",
      " 29  daily_temp_MAX_Feb  38661 non-null  float64\n",
      " 30  daily_temp_MAX_Mar  38661 non-null  float64\n",
      " 31  daily_temp_MAX_Apr  38661 non-null  float64\n",
      " 32  daily_temp_MAX_May  38661 non-null  float64\n",
      " 33  daily_temp_MAX_Jun  38661 non-null  float64\n",
      " 34  daily_temp_MAX_Jul  38661 non-null  float64\n",
      " 35  daily_temp_MAX_Aug  38661 non-null  float64\n",
      " 36  daily_temp_MAX_Sep  38661 non-null  float64\n",
      " 37  daily_temp_MAX_Oct  38661 non-null  float64\n",
      " 38  daily_temp_MAX_Nov  38661 non-null  float64\n",
      " 39  daily_temp_MAX_Dec  38661 non-null  float64\n",
      " 40  daily_temp_MIN_Jan  38590 non-null  float64\n",
      " 41  daily_temp_MIN_Feb  38590 non-null  float64\n",
      " 42  daily_temp_MIN_Mar  38590 non-null  float64\n",
      " 43  daily_temp_MIN_Apr  38590 non-null  float64\n",
      " 44  daily_temp_MIN_May  38590 non-null  float64\n",
      " 45  daily_temp_MIN_Jun  38590 non-null  float64\n",
      " 46  daily_temp_MIN_Jul  38590 non-null  float64\n",
      " 47  daily_temp_MIN_Aug  38590 non-null  float64\n",
      " 48  daily_temp_MIN_Sep  38590 non-null  float64\n",
      " 49  daily_temp_MIN_Oct  38590 non-null  float64\n",
      " 50  daily_temp_MIN_Nov  38590 non-null  float64\n",
      " 51  daily_temp_MIN_Dec  38590 non-null  float64\n",
      " 52  humidity_Jan        4508 non-null   float64\n",
      " 53  humidity_Feb        4508 non-null   float64\n",
      " 54  humidity_Mar        4508 non-null   float64\n",
      " 55  humidity_Apr        4508 non-null   float64\n",
      " 56  humidity_May        4508 non-null   float64\n",
      " 57  humidity_Jun        4508 non-null   float64\n",
      " 58  humidity_Jul        4508 non-null   float64\n",
      " 59  humidity_Aug        4508 non-null   float64\n",
      " 60  humidity_Sep        4508 non-null   float64\n",
      " 61  humidity_Oct        4508 non-null   float64\n",
      " 62  humidity_Nov        4508 non-null   float64\n",
      " 63  humidity_Dec        4508 non-null   float64\n",
      "dtypes: float64(60), int64(2), object(2)\n",
      "memory usage: 19.7+ MB\n"
     ]
    }
   ],
   "source": [
    "merged_weather_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e7f3ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe to CSV\n",
    "merged_weather_df.to_csv('data\\clean\\merged_weather.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d273f923",
   "metadata": {},
   "source": [
    "Next we will filter out wine data that have matching location and vintages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffcda19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wine Name</th>\n",
       "      <th>Region 1</th>\n",
       "      <th>Region 2</th>\n",
       "      <th>Region 3</th>\n",
       "      <th>Country</th>\n",
       "      <th>Score</th>\n",
       "      <th>Price</th>\n",
       "      <th>Winery</th>\n",
       "      <th>Variety</th>\n",
       "      <th>Vintage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Bodegas Dios Baco S.L. NV 1970 Oxford Pedro Xi...</td>\n",
       "      <td>Andalucia</td>\n",
       "      <td></td>\n",
       "      <td>Jerez</td>\n",
       "      <td>Spain</td>\n",
       "      <td>85</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Bodegas Dios Baco S.L.</td>\n",
       "      <td>Sherry</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Adega de Favaios 1980  Moscatel do Douro</td>\n",
       "      <td></td>\n",
       "      <td>Moscatel do Douro</td>\n",
       "      <td></td>\n",
       "      <td>Portugal</td>\n",
       "      <td>93</td>\n",
       "      <td>137.0</td>\n",
       "      <td>Adega de Favaios</td>\n",
       "      <td>Moscatel</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Adega de Favaios 1980 Moscatel (Moscatel do Do...</td>\n",
       "      <td></td>\n",
       "      <td>Moscatel do Douro</td>\n",
       "      <td></td>\n",
       "      <td>Portugal</td>\n",
       "      <td>93</td>\n",
       "      <td>137.0</td>\n",
       "      <td>Adega de Favaios</td>\n",
       "      <td>Muscat</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Cuva Vella 1980 Vintage Muscat (Valencia)</td>\n",
       "      <td>Levante</td>\n",
       "      <td></td>\n",
       "      <td>Valencia</td>\n",
       "      <td>Spain</td>\n",
       "      <td>90</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Cuva Vella</td>\n",
       "      <td>Muscat</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Moulin Touchais 1982 Chenin Blanc (Coteaux du ...</td>\n",
       "      <td>Loire Valley</td>\n",
       "      <td></td>\n",
       "      <td>Coteaux du Layon</td>\n",
       "      <td>France</td>\n",
       "      <td>95</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Moulin Touchais</td>\n",
       "      <td>Chenin Blanc</td>\n",
       "      <td>1982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Wine Name      Region 1  \\\n",
       "43  Bodegas Dios Baco S.L. NV 1970 Oxford Pedro Xi...     Andalucia   \n",
       "75           Adega de Favaios 1980  Moscatel do Douro                 \n",
       "77  Adega de Favaios 1980 Moscatel (Moscatel do Do...                 \n",
       "79          Cuva Vella 1980 Vintage Muscat (Valencia)       Levante   \n",
       "87  Moulin Touchais 1982 Chenin Blanc (Coteaux du ...  Loire Valley   \n",
       "\n",
       "             Region 2          Region 3   Country  Score  Price  \\\n",
       "43                                Jerez     Spain     85   40.0   \n",
       "75  Moscatel do Douro                    Portugal     93  137.0   \n",
       "77  Moscatel do Douro                    Portugal     93  137.0   \n",
       "79                             Valencia     Spain     90   65.0   \n",
       "87                     Coteaux du Layon    France     95   64.0   \n",
       "\n",
       "                    Winery       Variety  Vintage  \n",
       "43  Bodegas Dios Baco S.L.        Sherry     1970  \n",
       "75        Adega de Favaios      Moscatel     1980  \n",
       "77        Adega de Favaios        Muscat     1980  \n",
       "79              Cuva Vella        Muscat     1980  \n",
       "87         Moulin Touchais  Chenin Blanc     1982  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Dataframes\n",
    "wine_data = pd.read_csv('data/clean/cleaned_combined_wine_data.csv')\n",
    "merged_weather_df = pd.read_csv('data\\clean\\merged_weather.csv')\n",
    "\n",
    "# Create a temporary DataFrame with unique city-country pairs\n",
    "unique_city_country = merged_weather_df[['City', 'Country']].drop_duplicates()\n",
    "unique_city_country['City'] = unique_city_country['City'].str.upper()\n",
    "unique_city_country['City Words'] = unique_city_country['City'].apply(lambda x: x.split())\n",
    "\n",
    "# Function to check for any matching word and country match\n",
    "def any_matching_word_and_country(row, city_country_df):\n",
    "    for region_key in ['Region 1', 'Region 2', 'Region 3']:\n",
    "        region = row[region_key]\n",
    "        if pd.notna(region):\n",
    "            region_words = set(region.upper().split())\n",
    "            for _, city_country_row in city_country_df.iterrows():\n",
    "                if any(word in region_words for word in city_country_row['City Words']) and row['Country'].upper() == city_country_row['Country'].upper():\n",
    "                    return True\n",
    "    return False\n",
    "\n",
    "# Ensure all relevant columns are strings and handle NaNs\n",
    "wine_data[['Region 1', 'Region 2', 'Region 3']] = wine_data[['Region 1', 'Region 2', 'Region 3']].fillna('').astype(str)\n",
    "wine_data['Country'] = wine_data['Country'].fillna('').astype(str)\n",
    "\n",
    "# Filter wine_data\n",
    "filtered_wine_data = wine_data[wine_data.apply(lambda row: any_matching_word_and_country(row, unique_city_country), axis=1)]\n",
    "\n",
    "# Check result\n",
    "filtered_wine_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77a49ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16760 entries, 0 to 16759\n",
      "Data columns (total 10 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Wine Name  16760 non-null  object \n",
      " 1   Region 1   16760 non-null  object \n",
      " 2   Region 2   16760 non-null  object \n",
      " 3   Region 3   16760 non-null  object \n",
      " 4   Country    16760 non-null  object \n",
      " 5   Score      16760 non-null  int64  \n",
      " 6   Price      15406 non-null  float64\n",
      " 7   Winery     16760 non-null  object \n",
      " 8   Variety    16705 non-null  object \n",
      " 9   Vintage    16760 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(7)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Reset the index of the DataFrame\n",
    "filtered_wine_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Check result\n",
    "filtered_wine_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18f92992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe to CSV\n",
    "filtered_wine_data.to_csv(r'data\\clean\\filtered_wine_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2edb5d",
   "metadata": {},
   "source": [
    "With the low amount of match rate, we would need to approach this differently. We would need to use a weather API to obtain the weather information for wines that are missing related weather data. Keep in mind, some wines don't have an associated specific city and some wines just have a wine region. So what would make more sense is to have an api look up the geocoordinates of the wine region and then plug it into a weather API to get the necessary information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9014cab",
   "metadata": {},
   "source": [
    "## Implementing an API Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d081901",
   "metadata": {},
   "source": [
    "The following script uses Bing API to grab geocoordinates of regions mentioned in our list of wines, then uses the geocoordinates to grab climate data from NOAA api. Since we are using free service level of these APIs we need the script to stop when we hit the daily request limit. \n",
    "\n",
    "To start off let's create a proof of concent test script that tests out all the logic we need for our full script. The following script samples a random row from our clean wine csv file and try to return weather databased on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bfcced65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Address Found: Gadais Pere et Fils Wines Loire Valley France, Loire Valley, Indre-et-Loire, France, Loire Valley, Indre-et-Loire, France, [47.39888763, 0.7027778]\n",
      "Averaged Weather Data: {'TMAX_1': 30.84444444444444, 'TMAX_2': 37.166666666666664, 'TMAX_3': 46.288888888888884, 'TMAX_4': 59.333333333333336, 'TMAX_5': 68.56, 'TMAX_6': 79.12, 'TMAX_7': 87.59, 'TMAX_8': 83.44, 'TMAX_9': 75.41, 'TMAX_10': 64.24444444444445, 'TMAX_11': 52.57777777777778, 'TMAX_12': 42.1, 'TMIN_1': 13.211111111111114, 'TMIN_2': 16.266666666666666, 'TMIN_3': 26.54444444444444, 'TMIN_4': 37.5875, 'TMIN_5': 48.279999999999994, 'TMIN_6': 57.160000000000004, 'TMIN_7': 63.89, 'TMIN_8': 60.03000000000001, 'TMIN_9': 51.85000000000001, 'TMIN_10': 41.22222222222222, 'TMIN_11': 30.299999999999997, 'TMIN_12': 22.766666666666666, 'PRCP_1': 1.59, 'PRCP_2': 1.9749999999999999, 'PRCP_3': 2.6, 'PRCP_4': 4.241428571428572, 'PRCP_5': 4.363333333333333, 'PRCP_6': 3.397777777777778, 'PRCP_7': 3.9377777777777783, 'PRCP_8': 6.445555555555555, 'PRCP_9': 2.8355555555555556, 'PRCP_10': 3.3150000000000004, 'PRCP_11': 2.5100000000000002, 'PRCP_12': 2.4699999999999998, 'TAVG_1': 22.011111111111113, 'TAVG_2': 26.71111111111111, 'TAVG_3': 36.41111111111111, 'TAVG_4': 47.9, 'TAVG_5': 58.419999999999995, 'TAVG_6': 68.13000000000001, 'TAVG_7': 75.74000000000001, 'TAVG_8': 71.74000000000001, 'TAVG_9': 63.64, 'TAVG_10': 52.73333333333333, 'TAVG_11': 41.44444444444445, 'TAVG_12': 32.44444444444444}\n"
     ]
    }
   ],
   "source": [
    "# Constants for rate limiting\n",
    "NOAA_RATE_LIMIT = 0.2  # seconds between requests\n",
    "NOAA_DAILY_LIMIT = 10000\n",
    "noaa_request_count = 0  # Initialize request count\n",
    "\n",
    "# Function to clean and prepare keywords\n",
    "def clean_keywords(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    # Remove text within parentheses\n",
    "    text = re.sub(r'\\(.*?\\)', '', text).strip()\n",
    "    return text\n",
    "\n",
    "# Function to create variations of the winery name\n",
    "def create_winery_variations(winery):\n",
    "    variations = [\"Wines\", \"Wine\", \"Vineyard\", \"Estate\", \"Winery\", \"Vineyards\"]\n",
    "    return [f\"{winery} {variation}\" for variation in variations] + [winery]\n",
    "\n",
    "# Function to construct search query\n",
    "def construct_query(row, winery_variations):\n",
    "    regions = [clean_keywords(row['Region 1']), clean_keywords(row['Region 2']), clean_keywords(row['Region 3'])]\n",
    "    country = clean_keywords(row['Country'])\n",
    "\n",
    "    # Construct different combinations\n",
    "    combinations = []\n",
    "    for winery_variation in winery_variations:\n",
    "        for i in range(len(regions)):\n",
    "            for j in range(i, len(regions)):\n",
    "                query_parts = [winery_variation] + regions[i:j+1] + [country]\n",
    "                combinations.append(' '.join(filter(None, query_parts)))\n",
    "\n",
    "    return combinations, regions, country\n",
    "\n",
    "# Function to calculate the bounding box\n",
    "def get_gps_bounding_box(latitude, longitude, deg_lat=1.0, deg_lon=1.0):\n",
    "    n = min(90, latitude + deg_lat)\n",
    "    s = max(-90, latitude - deg_lat)\n",
    "    e = min(180, longitude + deg_lon)\n",
    "    w = max(-180, longitude - deg_lon)\n",
    "    return n, w, s, e\n",
    "\n",
    "# Function to find weather stations by bounding box with rate limiting\n",
    "def get_stations_by_bounding_box(lat, lon, api_token):\n",
    "    global noaa_request_count\n",
    "    if noaa_request_count >= NOAA_DAILY_LIMIT:\n",
    "        print(\"NOAA daily request limit reached.\")\n",
    "        return []\n",
    "\n",
    "    time.sleep(NOAA_RATE_LIMIT)\n",
    "    n, w, s, e = get_gps_bounding_box(lat, lon)\n",
    "    url = f\"https://www.ncei.noaa.gov/access/services/search/v1/data?dataset=global-summary-of-the-month&boundingBox={n},{w},{s},{e}&dataTypes=TMIN,TMAX,PRCP,TAVG&limit=10&offset=0\"\n",
    "    headers = {'token': api_token}\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)  # 10 seconds timeout\n",
    "        noaa_request_count += 1\n",
    "        if response.status_code == 200:\n",
    "            stations_data = response.json().get('results', [])\n",
    "            valid_stations = []\n",
    "            for station in stations_data:\n",
    "                station_id = station['id']\n",
    "                # Extract the valid part of the station ID\n",
    "                valid_station_id = station_id.split(':')[1].split('.')[0]\n",
    "                valid_stations.append(valid_station_id)\n",
    "            return valid_stations\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\"NOAA request timed out.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in NOAA request: {e}\")\n",
    "    return []\n",
    "\n",
    "# Function to get monthly climate data for a station with rate limiting\n",
    "def get_mly_climate_data_for_station(station_id, vintage_year, api_token):\n",
    "    global noaa_request_count\n",
    "    if noaa_request_count >= NOAA_DAILY_LIMIT:\n",
    "        print(\"NOAA daily request limit reached.\")\n",
    "        return {}\n",
    "\n",
    "    start_date = f\"{vintage_year}-01-01\"\n",
    "    end_date = f\"{vintage_year}-12-31\"\n",
    "    time.sleep(NOAA_RATE_LIMIT)\n",
    "    url = f\"https://www.ncei.noaa.gov/access/services/data/v1?dataset=global-summary-of-the-month&dataTypes=TMIN,TMAX,PRCP,TAVG&stations={station_id}&startDate={start_date}&endDate={end_date}&format=json&units=standard&includeAttributes=false\"\n",
    "    headers = {'token': api_token}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        noaa_request_count += 1\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            monthly_data_raw = response.json()\n",
    "            monthly_data = {f\"{data_type}_{month}\": [] for data_type in ['TMIN', 'TMAX', 'PRCP', 'TAVG'] for month in range(1, 13)}\n",
    "\n",
    "            for record in monthly_data_raw:\n",
    "                month = int(record['DATE'].split('-')[1])\n",
    "                for data_type in ['TMIN', 'TMAX', 'PRCP', 'TAVG']:\n",
    "                    if record.get(data_type) is not None:\n",
    "                        monthly_data[f\"{data_type}_{month}\"].append(float(record[data_type]))\n",
    "\n",
    "            # Averaging the data\n",
    "            averaged_data = {key: sum(values) / len(values) if values else None for key, values in monthly_data.items()}\n",
    "            return averaged_data\n",
    "\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\"NOAA request timed out.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in NOAA request: {e}\")\n",
    "    return {}\n",
    "\n",
    "# Function to check if address matches the country\n",
    "def is_country_match(country, address):\n",
    "    return country.lower() in address.lower()\n",
    "\n",
    "# Function to check if address matches any of the regions and country\n",
    "def is_region_country_match(regions, country, address):\n",
    "    region_country_text = \" \".join([r for r in regions if r] + [country]).lower()\n",
    "    return any(region.lower() in address.lower() for region in region_country_text.split()) and country.lower() in address.lower()\n",
    "\n",
    "# Read CSV file\n",
    "df = pd.read_csv('data/clean/cleaned_combined_wine_data.csv')\n",
    "\n",
    "# Select a random row\n",
    "random_row = df.sample().iloc[0]\n",
    "\n",
    "# Get winery name and create variations\n",
    "winery = clean_keywords(random_row['Winery'])\n",
    "winery_variations = create_winery_variations(winery)\n",
    "\n",
    "# Construct queries\n",
    "queries, regions, country = construct_query(random_row, winery_variations)\n",
    "\n",
    "# Bing Maps API Key\n",
    "bing_maps_key = 'Insert Key'\n",
    "\n",
    "# NOAA API token\n",
    "noaa_api_token = \"Insert Key\"\n",
    "\n",
    "# Function to search using Bing Maps API\n",
    "def search_address(query):\n",
    "    url = f\"http://dev.virtualearth.net/REST/v1/Locations?query={query}&key={bing_maps_key}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    return None\n",
    "\n",
    "# Function to extract address, location name, and geocoordinates from the result\n",
    "def extract_address_info(result):\n",
    "    if result and 'resourceSets' in result:\n",
    "        resources = result['resourceSets'][0]['resources']\n",
    "        if resources:\n",
    "            location_name = resources[0]['name']\n",
    "            address = resources[0]['address']['formattedAddress']\n",
    "            coordinates = resources[0]['point']['coordinates'] if 'point' in resources[0] else None\n",
    "            return location_name, address, coordinates\n",
    "    return None, None, None\n",
    "\n",
    "# Function to check if the winery name is part of the business name in the location\n",
    "def is_correct_business_match(winery_variations, location_name, address, country):\n",
    "    return any(winery_variation.lower() in location_name.lower() for winery_variation in winery_variations) and is_country_match(country, address)\n",
    "\n",
    "# Function to find the best match for the winery\n",
    "def find_best_match(queries, winery_variations, regions, country):\n",
    "    best_match = None\n",
    "    for query in queries:\n",
    "        result = search_address(query)\n",
    "        location_name, address, coordinates = extract_address_info(result)\n",
    "        if location_name and address and coordinates:\n",
    "            if is_correct_business_match(winery_variations, location_name, address, country):\n",
    "                return (query, location_name, address, coordinates)\n",
    "            elif is_region_country_match(regions, country, address) and not best_match:\n",
    "                best_match = (query, location_name, address, coordinates)\n",
    "\n",
    "    return best_match\n",
    "\n",
    "# Find the best match\n",
    "best_match = find_best_match(queries, winery_variations, regions, country)\n",
    "if best_match:\n",
    "    query, location_name, address, coordinates = best_match\n",
    "    print(f\"Address Found: {query}, {location_name}, {address}, {coordinates}\")\n",
    "    lat, lon = coordinates\n",
    "    station_results = get_stations_by_bounding_box(lat, lon, noaa_api_token)\n",
    "\n",
    "    aggregated_weather_data = {\n",
    "        \"TMAX\": defaultdict(list),\n",
    "        \"TMIN\": defaultdict(list),\n",
    "        \"PRCP\": defaultdict(list),\n",
    "        \"TAVG\": defaultdict(list)\n",
    "    }\n",
    "\n",
    "    # Collecting data from each station\n",
    "    for station_id in station_results:\n",
    "        station_weather_data = get_mly_climate_data_for_station(station_id, vintage_year, noaa_api_token)\n",
    "        if station_weather_data:\n",
    "            for key, value in station_weather_data.items():\n",
    "                if value is not None:\n",
    "                    metric, month = key.split('_')\n",
    "                    aggregated_weather_data[metric][int(month)].append(value)\n",
    "\n",
    "    # Averaging the data across all stations\n",
    "    averaged_weather_data = {}\n",
    "    for metric, monthly_values in aggregated_weather_data.items():\n",
    "        for month in range(1, 13):\n",
    "            if monthly_values[month]:\n",
    "                avg_value = sum(monthly_values[month]) / len(monthly_values[month])\n",
    "                averaged_weather_data[f\"{metric}_{month}\"] = avg_value\n",
    "            else:\n",
    "                averaged_weather_data[f\"{metric}_{month}\"] = None\n",
    "\n",
    "    print(\"Averaged Weather Data:\", averaged_weather_data)\n",
    "else:\n",
    "    print(\"No valid address found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5494c42",
   "metadata": {},
   "source": [
    "After running the script a few times, it is obvious it is not perfect. Not all locations can be pinpointed to the exact city or village that each wine is produced. This is mostly the fault of the wine data we have, since not all data have detailed wine location information. This could skew our data to higher class wines where more detailed location information is provided. However the good news is that there are low class wines from smaller countries where even if there isn't perfect location data, the difference in weather data is within a margin of error (unless there are some geographic feature that makes the are have a different weather pattern). Also there are wines where only the province or state is listed, so using the averaged weather data in the area would give a good indication, since these wines are meant to represent that they are made with grapes all across the state, county, or province.\n",
    "\n",
    "Next we can write a full script that iterate through a CSV. Here to make sure we can get a result to make sure the script works, I've created a CSV file that contains a small sample of wines for the script to be tested on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d75b4a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOAA request timed out.\n",
      "NOAA request timed out.\n",
      "No valid address found for Wiese & Krohn\n",
      "NOAA request timed out.\n",
      "No valid address found for W. & J. Graham's\n",
      "No valid address found for Wiese & Krohn\n",
      "No valid address found for Wiese & Krohn\n",
      "No valid address found for W. & J. Graham's\n",
      "No valid address found for W. & J. Graham's\n",
      "NOAA request timed out.\n",
      "NOAA request timed out.\n",
      "NOAA request timed out.\n",
      "NOAA request timed out.\n",
      "NOAA request timed out.\n",
      "NOAA request timed out.\n",
      "No valid address found for Wiese & Krohn\n",
      "No valid address found for Wiese & Krohn\n",
      "No valid address found for Sebastiani\n",
      "NOAA request timed out.\n",
      "No valid address found for Sebastiani\n",
      "No valid address found for Sebastiani\n",
      "No valid address found for Heidsieck & Co Monopole\n",
      "No valid address found for Heidsieck & Co Monopole\n",
      "No valid address found for Argyle\n",
      "No valid address found for Heidsieck & Co Monopole\n",
      "NOAA request timed out.\n",
      "No valid address found for Wellington\n",
      "NOAA request timed out.\n",
      "NOAA request timed out.\n",
      "No valid address found for Gan Eden\n",
      "NOAA request timed out.\n",
      "NOAA request timed out.\n",
      "NOAA request timed out.\n",
      "NOAA request timed out.\n",
      "No valid address found for Argyle\n",
      "No valid address found for Gloria Ferrer\n",
      "           Winery                                          Wine Name  Vintage  \\\n",
      "0           Calem              Calem 1961 Colheita Tawny Port (Port)     1961   \n",
      "1           Calem                  Calem 1961 Colheita Tawny  (Port)     1961   \n",
      "2         Warre's             Warre's 1961 Reserve Tawny Port (Port)     1961   \n",
      "3  Cossart Gordon                 Cossart Gordon 1962 Bual (Madeira)     1962   \n",
      "4     Van Zellers  Van Zellers 1962 Palmer Colheita White Port (P...     1962   \n",
      "\n",
      "  Location Name   Address   Latitude  Longitude     TMAX_1     TMAX_2  \\\n",
      "0      Portugal  Portugal  39.682198  -7.968288  33.366667  43.200000   \n",
      "1      Portugal  Portugal  39.682198  -7.968288  36.975000  47.466667   \n",
      "2      Portugal  Portugal  39.682198  -7.968288  36.975000  47.466667   \n",
      "3      Portugal  Portugal  39.682198  -7.968288  37.066667  39.875000   \n",
      "4      Portugal  Portugal  39.682198  -7.968288  37.066667  39.875000   \n",
      "\n",
      "      TMAX_3  ...     TAVG_3     TAVG_4     TAVG_5     TAVG_6     TAVG_7  \\\n",
      "0  51.133333  ...  41.166667  44.566667  55.766667  68.633333  72.833333   \n",
      "1  54.350000  ...  44.050000  46.825000  57.875000  69.650000  74.025000   \n",
      "2  54.350000  ...  44.050000  46.825000  57.875000  69.650000  74.025000   \n",
      "3  47.700000  ...  39.200000  51.175000  66.425000  70.025000  72.275000   \n",
      "4  47.700000  ...  39.200000  51.175000  66.425000  70.025000  72.275000   \n",
      "\n",
      "   TAVG_8  TAVG_9    TAVG_10    TAVG_11    TAVG_12  \n",
      "0  73.800  64.900  53.433333  39.066667  26.033333  \n",
      "1  74.475  66.975  54.825000  42.400000  29.850000  \n",
      "2  74.475  66.975  54.825000  42.400000  29.850000  \n",
      "3  73.425  63.825  57.425000  42.350000  29.350000  \n",
      "4  73.425  63.825  57.425000  42.350000  29.350000  \n",
      "\n",
      "[5 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "# Constants for rate limiting\n",
    "NOAA_RATE_LIMIT = 0.2  # seconds between requests\n",
    "NOAA_DAILY_LIMIT = 10000\n",
    "noaa_request_count = 0  # Initialize request count\n",
    "\n",
    "# Bing Maps API Key (replace with your key)\n",
    "bing_maps_key = 'Insert Key'\n",
    "\n",
    "# NOAA API token (replace with your token)\n",
    "noaa_api_token = 'Insert Key'\n",
    "\n",
    "# Function to clean and prepare keywords\n",
    "def clean_keywords(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    # Remove text within parentheses\n",
    "    text = re.sub(r'\\(.*?\\)', '', text).strip()\n",
    "    return text\n",
    "\n",
    "# Function to create variations of the winery name\n",
    "def create_winery_variations(winery):\n",
    "    variations = [\"Wines\", \"Wine\", \"Vineyard\", \"Estate\", \"Winery\", \"Vineyards\"]\n",
    "    return [f\"{winery} {variation}\" for variation in variations] + [winery]\n",
    "\n",
    "# Function to construct search query\n",
    "def construct_query(row, winery_variations):\n",
    "    regions = [clean_keywords(row['Region 1']), clean_keywords(row['Region 2']), clean_keywords(row['Region 3'])]\n",
    "    country = clean_keywords(row['Country'])\n",
    "\n",
    "    # Construct different combinations\n",
    "    combinations = []\n",
    "    for winery_variation in winery_variations:\n",
    "        for i in range(len(regions)):\n",
    "            for j in range(i, len(regions)):\n",
    "                query_parts = [winery_variation] + regions[i:j+1] + [country]\n",
    "                combinations.append(' '.join(filter(None, query_parts)))\n",
    "\n",
    "    return combinations, regions, country\n",
    "\n",
    "# Function to calculate the bounding box\n",
    "def get_gps_bounding_box(latitude, longitude, deg_lat=1.0, deg_lon=1.0):\n",
    "    n = min(90, latitude + deg_lat)\n",
    "    s = max(-90, latitude - deg_lat)\n",
    "    e = min(180, longitude + deg_lon)\n",
    "    w = max(-180, longitude - deg_lon)\n",
    "    return n, w, s, e\n",
    "\n",
    "# Function to find weather stations by bounding box with rate limiting\n",
    "def get_stations_by_bounding_box(lat, lon, api_token):\n",
    "    global noaa_request_count\n",
    "    if noaa_request_count >= NOAA_DAILY_LIMIT:\n",
    "        print(\"NOAA daily request limit reached.\")\n",
    "        return []\n",
    "\n",
    "    time.sleep(NOAA_RATE_LIMIT)\n",
    "    n, w, s, e = get_gps_bounding_box(lat, lon)\n",
    "    url = f\"https://www.ncei.noaa.gov/access/services/search/v1/data?dataset=global-summary-of-the-month&boundingBox={n},{w},{s},{e}&dataTypes=TMIN,TMAX,PRCP,TAVG&limit=10&offset=0\"\n",
    "    headers = {'token': api_token}\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)  # 10 seconds timeout\n",
    "        noaa_request_count += 1\n",
    "        if response.status_code == 200:\n",
    "            stations_data = response.json().get('results', [])\n",
    "            valid_stations = []\n",
    "            for station in stations_data:\n",
    "                station_id = station['id']\n",
    "                # Extract the valid part of the station ID\n",
    "                valid_station_id = station_id.split(':')[1].split('.')[0]\n",
    "                valid_stations.append(valid_station_id)\n",
    "            return valid_stations\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\"NOAA request timed out.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in NOAA request: {e}\")\n",
    "    return []\n",
    "\n",
    "# Function to check if address matches the country\n",
    "def is_country_match(country, address):\n",
    "    return country.lower() in address.lower()\n",
    "\n",
    "# Function to check if address matches any of the regions and country\n",
    "def is_region_country_match(regions, country, address):\n",
    "    region_country_text = \" \".join([r for r in regions if r] + [country]).lower()\n",
    "    return any(region.lower() in address.lower() for region in region_country_text.split()) and country.lower() in address.lower()\n",
    "\n",
    "# Function to search using Bing Maps API\n",
    "def search_address(query):\n",
    "    url = f\"http://dev.virtualearth.net/REST/v1/Locations?query={query}&key={bing_maps_key}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    return None\n",
    "\n",
    "# Function to get monthly climate data for a station with rate limiting\n",
    "def get_mly_climate_data_for_station(station_id, vintage_year, api_token):\n",
    "    global noaa_request_count\n",
    "    if noaa_request_count >= NOAA_DAILY_LIMIT:\n",
    "        print(\"NOAA daily request limit reached.\")\n",
    "        return {}\n",
    "\n",
    "    start_date = f\"{vintage_year}-01-01\"\n",
    "    end_date = f\"{vintage_year}-12-31\"\n",
    "    time.sleep(NOAA_RATE_LIMIT)\n",
    "    url = f\"https://www.ncei.noaa.gov/access/services/data/v1?dataset=global-summary-of-the-month&dataTypes=TMIN,TMAX,PRCP,TAVG&stations={station_id}&startDate={start_date}&endDate={end_date}&format=json&units=standard&includeAttributes=false\"\n",
    "    headers = {'token': api_token}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        noaa_request_count += 1\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            monthly_data_raw = response.json()\n",
    "            monthly_data = {f\"{data_type}_{month}\": [] for data_type in ['TMIN', 'TMAX', 'PRCP', 'TAVG'] for month in range(1, 13)}\n",
    "\n",
    "            for record in monthly_data_raw:\n",
    "                month = int(record['DATE'].split('-')[1])\n",
    "                for data_type in ['TMIN', 'TMAX', 'PRCP', 'TAVG']:\n",
    "                    if record.get(data_type) is not None:\n",
    "                        monthly_data[f\"{data_type}_{month}\"].append(float(record[data_type]))\n",
    "\n",
    "            # Averaging the data\n",
    "            averaged_data = {key: sum(values) / len(values) if values else None for key, values in monthly_data.items()}\n",
    "            return averaged_data\n",
    "\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\"NOAA request timed out.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in NOAA request: {e}\")\n",
    "    return {}\n",
    "\n",
    "# Function to extract address, location name, and geocoordinates from the result\n",
    "def extract_address_info(result):\n",
    "    if result and 'resourceSets' in result:\n",
    "        resources = result['resourceSets'][0]['resources']\n",
    "        if resources:\n",
    "            location_name = resources[0]['name']\n",
    "            address = resources[0]['address']['formattedAddress']\n",
    "            coordinates = resources[0]['point']['coordinates'] if 'point' in resources[0] else None\n",
    "            return location_name, address, coordinates\n",
    "    return None, None, None\n",
    "\n",
    "# Function to check if the winery name is part of the business name in the location\n",
    "def is_correct_business_match(winery_variations, location_name, address, country):\n",
    "    return any(winery_variation.lower() in location_name.lower() for winery_variation in winery_variations) and is_country_match(country, address)\n",
    "\n",
    "# Function to find the best match for the winery\n",
    "def find_best_match(queries, winery_variations, regions, country):\n",
    "    best_match = None\n",
    "    for query in queries:\n",
    "        result = search_address(query)\n",
    "        location_name, address, coordinates = extract_address_info(result)\n",
    "        if location_name and address and coordinates:\n",
    "            if is_correct_business_match(winery_variations, location_name, address, country):\n",
    "                return (query, location_name, address, coordinates)\n",
    "            elif is_region_country_match(regions, country, address) and not best_match:\n",
    "                best_match = (query, location_name, address, coordinates)\n",
    "\n",
    "    return best_match\n",
    "\n",
    "# Function to process each wine entry\n",
    "def process_wine_entry(row):\n",
    "    winery = clean_keywords(row['Winery'])\n",
    "    winery_variations = create_winery_variations(winery)\n",
    "    queries, regions, country = construct_query(row, winery_variations)\n",
    "\n",
    "    best_match = find_best_match(queries, winery_variations, regions, country)\n",
    "    if best_match:\n",
    "        query, location_name, address, coordinates = best_match\n",
    "        lat, lon = coordinates\n",
    "        station_results = get_stations_by_bounding_box(lat, lon, noaa_api_token)\n",
    "\n",
    "        aggregated_weather_data = {\n",
    "            \"TMAX\": defaultdict(list),\n",
    "            \"TMIN\": defaultdict(list),\n",
    "            \"PRCP\": defaultdict(list),\n",
    "            \"TAVG\": defaultdict(list)\n",
    "        }\n",
    "\n",
    "        for station_id in station_results:\n",
    "            station_weather_data = get_mly_climate_data_for_station(station_id, row['Vintage'], noaa_api_token)\n",
    "            if station_weather_data:\n",
    "                for key, value in station_weather_data.items():\n",
    "                    if value is not None:\n",
    "                        metric, month = key.split('_')\n",
    "                        aggregated_weather_data[metric][int(month)].append(value)\n",
    "\n",
    "        averaged_weather_data = {}\n",
    "        for metric, monthly_values in aggregated_weather_data.items():\n",
    "            for month in range(1, 13):\n",
    "                if monthly_values[month]:\n",
    "                    avg_value = sum(monthly_values[month]) / len(monthly_values[month])\n",
    "                    averaged_weather_data[f\"{metric}_{month}\"] = avg_value\n",
    "                else:\n",
    "                    averaged_weather_data[f\"{metric}_{month}\"] = None\n",
    "\n",
    "        return {\n",
    "            \"Winery\": row['Winery'],\n",
    "            \"Wine Name\": row['Wine Name'],\n",
    "            \"Vintage\": row['Vintage'],\n",
    "            \"Location Name\": location_name,\n",
    "            \"Address\": address,\n",
    "            \"Latitude\": lat,\n",
    "            \"Longitude\": lon,\n",
    "            **averaged_weather_data\n",
    "        }\n",
    "    else:\n",
    "        print(f\"No valid address found for {row['Winery']}\")\n",
    "        return None\n",
    "\n",
    "# Read CSV file\n",
    "wine_data = pd.read_csv('data/clean/cleaned_combined_wine_data.csv')\n",
    "\n",
    "# Process each wine entry\n",
    "processed_wine_data = []\n",
    "for _, row in wine_data.iterrows():\n",
    "    processed_data = process_wine_entry(row)\n",
    "    if processed_data:\n",
    "        processed_wine_data.append(processed_data)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "weather_enhanced_wine_data = pd.DataFrame(processed_wine_data)\n",
    "\n",
    "# Save the results\n",
    "weather_enhanced_wine_data.to_csv('data/intermediate/weather_enhanced_wine_data.csv', index=False)\n",
    "\n",
    "# Display the results\n",
    "weather_enhanced_wine_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "791fdc97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Winery</th>\n",
       "      <th>Wine Name</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Location Name</th>\n",
       "      <th>Address</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>TMAX_1</th>\n",
       "      <th>TMAX_2</th>\n",
       "      <th>TMAX_3</th>\n",
       "      <th>...</th>\n",
       "      <th>TAVG_3</th>\n",
       "      <th>TAVG_4</th>\n",
       "      <th>TAVG_5</th>\n",
       "      <th>TAVG_6</th>\n",
       "      <th>TAVG_7</th>\n",
       "      <th>TAVG_8</th>\n",
       "      <th>TAVG_9</th>\n",
       "      <th>TAVG_10</th>\n",
       "      <th>TAVG_11</th>\n",
       "      <th>TAVG_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Calem</td>\n",
       "      <td>Calem 1961 Colheita Tawny Port (Port)</td>\n",
       "      <td>1961</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>39.682198</td>\n",
       "      <td>-7.968288</td>\n",
       "      <td>33.366667</td>\n",
       "      <td>43.200000</td>\n",
       "      <td>51.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>41.166667</td>\n",
       "      <td>44.566667</td>\n",
       "      <td>55.766667</td>\n",
       "      <td>68.633333</td>\n",
       "      <td>72.833333</td>\n",
       "      <td>73.800000</td>\n",
       "      <td>64.900000</td>\n",
       "      <td>53.433333</td>\n",
       "      <td>39.066667</td>\n",
       "      <td>26.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Calem</td>\n",
       "      <td>Calem 1961 Colheita Tawny  (Port)</td>\n",
       "      <td>1961</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>39.682198</td>\n",
       "      <td>-7.968288</td>\n",
       "      <td>36.975000</td>\n",
       "      <td>47.466667</td>\n",
       "      <td>54.350000</td>\n",
       "      <td>...</td>\n",
       "      <td>44.050000</td>\n",
       "      <td>46.825000</td>\n",
       "      <td>57.875000</td>\n",
       "      <td>69.650000</td>\n",
       "      <td>74.025000</td>\n",
       "      <td>74.475000</td>\n",
       "      <td>66.975000</td>\n",
       "      <td>54.825000</td>\n",
       "      <td>42.400000</td>\n",
       "      <td>29.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Warre's</td>\n",
       "      <td>Warre's 1961 Reserve Tawny Port (Port)</td>\n",
       "      <td>1961</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>39.682198</td>\n",
       "      <td>-7.968288</td>\n",
       "      <td>36.975000</td>\n",
       "      <td>47.466667</td>\n",
       "      <td>54.350000</td>\n",
       "      <td>...</td>\n",
       "      <td>44.050000</td>\n",
       "      <td>46.825000</td>\n",
       "      <td>57.875000</td>\n",
       "      <td>69.650000</td>\n",
       "      <td>74.025000</td>\n",
       "      <td>74.475000</td>\n",
       "      <td>66.975000</td>\n",
       "      <td>54.825000</td>\n",
       "      <td>42.400000</td>\n",
       "      <td>29.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cossart Gordon</td>\n",
       "      <td>Cossart Gordon 1962 Bual (Madeira)</td>\n",
       "      <td>1962</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>39.682198</td>\n",
       "      <td>-7.968288</td>\n",
       "      <td>37.066667</td>\n",
       "      <td>39.875000</td>\n",
       "      <td>47.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>39.200000</td>\n",
       "      <td>51.175000</td>\n",
       "      <td>66.425000</td>\n",
       "      <td>70.025000</td>\n",
       "      <td>72.275000</td>\n",
       "      <td>73.425000</td>\n",
       "      <td>63.825000</td>\n",
       "      <td>57.425000</td>\n",
       "      <td>42.350000</td>\n",
       "      <td>29.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Van Zellers</td>\n",
       "      <td>Van Zellers 1962 Palmer Colheita White Port (P...</td>\n",
       "      <td>1962</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>39.682198</td>\n",
       "      <td>-7.968288</td>\n",
       "      <td>37.066667</td>\n",
       "      <td>39.875000</td>\n",
       "      <td>47.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>39.200000</td>\n",
       "      <td>51.175000</td>\n",
       "      <td>66.425000</td>\n",
       "      <td>70.025000</td>\n",
       "      <td>72.275000</td>\n",
       "      <td>73.425000</td>\n",
       "      <td>63.825000</td>\n",
       "      <td>57.425000</td>\n",
       "      <td>42.350000</td>\n",
       "      <td>29.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Salon</td>\n",
       "      <td>Salon 1990 Le Mesnil Blanc de Blancs Brut Char...</td>\n",
       "      <td>1990</td>\n",
       "      <td>Salon-de-Provence, Bouches-du-Rhône, France</td>\n",
       "      <td>Salon-de-Provence, Bouches-du-Rhône, France</td>\n",
       "      <td>43.640297</td>\n",
       "      <td>5.086390</td>\n",
       "      <td>44.087500</td>\n",
       "      <td>43.911111</td>\n",
       "      <td>51.377778</td>\n",
       "      <td>...</td>\n",
       "      <td>41.055556</td>\n",
       "      <td>49.644444</td>\n",
       "      <td>57.144444</td>\n",
       "      <td>69.077778</td>\n",
       "      <td>72.777778</td>\n",
       "      <td>71.755556</td>\n",
       "      <td>65.711111</td>\n",
       "      <td>52.866667</td>\n",
       "      <td>43.655556</td>\n",
       "      <td>28.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Howard's Folly</td>\n",
       "      <td>Howard's Folly 1991 Casa Manoel Boullush White...</td>\n",
       "      <td>1991</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>39.682198</td>\n",
       "      <td>-7.968288</td>\n",
       "      <td>32.622222</td>\n",
       "      <td>44.622222</td>\n",
       "      <td>51.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>40.522222</td>\n",
       "      <td>51.766667</td>\n",
       "      <td>63.700000</td>\n",
       "      <td>70.666667</td>\n",
       "      <td>74.200000</td>\n",
       "      <td>73.155556</td>\n",
       "      <td>63.644444</td>\n",
       "      <td>52.166667</td>\n",
       "      <td>35.911111</td>\n",
       "      <td>32.855556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Moulin Touchais</td>\n",
       "      <td>Moulin Touchais 1991 Chenin Blanc (Coteaux du ...</td>\n",
       "      <td>1991</td>\n",
       "      <td>Loire Valley, Indre-et-Loire, France</td>\n",
       "      <td>Loire Valley, Indre-et-Loire, France</td>\n",
       "      <td>47.398888</td>\n",
       "      <td>0.702778</td>\n",
       "      <td>32.622222</td>\n",
       "      <td>44.622222</td>\n",
       "      <td>51.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>40.522222</td>\n",
       "      <td>51.766667</td>\n",
       "      <td>63.700000</td>\n",
       "      <td>70.666667</td>\n",
       "      <td>74.200000</td>\n",
       "      <td>73.155556</td>\n",
       "      <td>63.644444</td>\n",
       "      <td>52.166667</td>\n",
       "      <td>35.911111</td>\n",
       "      <td>32.855556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Montecillo</td>\n",
       "      <td>Montecillo 1991 Seleccion Especial Gran Reserv...</td>\n",
       "      <td>1991</td>\n",
       "      <td>Montecillo, Cantabria, Spain</td>\n",
       "      <td>Montecillo, Cantabria, Spain</td>\n",
       "      <td>42.774986</td>\n",
       "      <td>-3.975144</td>\n",
       "      <td>32.622222</td>\n",
       "      <td>44.622222</td>\n",
       "      <td>51.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>40.522222</td>\n",
       "      <td>51.766667</td>\n",
       "      <td>63.700000</td>\n",
       "      <td>70.666667</td>\n",
       "      <td>74.200000</td>\n",
       "      <td>73.155556</td>\n",
       "      <td>63.644444</td>\n",
       "      <td>52.166667</td>\n",
       "      <td>35.911111</td>\n",
       "      <td>32.855556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Blandy's</td>\n",
       "      <td>Blandy's 1991 Malmsey Malmsey (Madeira)</td>\n",
       "      <td>1991</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>39.682198</td>\n",
       "      <td>-7.968288</td>\n",
       "      <td>32.622222</td>\n",
       "      <td>44.622222</td>\n",
       "      <td>51.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>40.522222</td>\n",
       "      <td>51.766667</td>\n",
       "      <td>63.700000</td>\n",
       "      <td>70.666667</td>\n",
       "      <td>74.200000</td>\n",
       "      <td>73.155556</td>\n",
       "      <td>63.644444</td>\n",
       "      <td>52.166667</td>\n",
       "      <td>35.911111</td>\n",
       "      <td>32.855556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Winery                                          Wine Name  \\\n",
       "0              Calem              Calem 1961 Colheita Tawny Port (Port)   \n",
       "1              Calem                  Calem 1961 Colheita Tawny  (Port)   \n",
       "2            Warre's             Warre's 1961 Reserve Tawny Port (Port)   \n",
       "3     Cossart Gordon                 Cossart Gordon 1962 Bual (Madeira)   \n",
       "4        Van Zellers  Van Zellers 1962 Palmer Colheita White Port (P...   \n",
       "..               ...                                                ...   \n",
       "185            Salon  Salon 1990 Le Mesnil Blanc de Blancs Brut Char...   \n",
       "186   Howard's Folly  Howard's Folly 1991 Casa Manoel Boullush White...   \n",
       "187  Moulin Touchais  Moulin Touchais 1991 Chenin Blanc (Coteaux du ...   \n",
       "188       Montecillo  Montecillo 1991 Seleccion Especial Gran Reserv...   \n",
       "189         Blandy's            Blandy's 1991 Malmsey Malmsey (Madeira)   \n",
       "\n",
       "     Vintage                                Location Name  \\\n",
       "0       1961                                     Portugal   \n",
       "1       1961                                     Portugal   \n",
       "2       1961                                     Portugal   \n",
       "3       1962                                     Portugal   \n",
       "4       1962                                     Portugal   \n",
       "..       ...                                          ...   \n",
       "185     1990  Salon-de-Provence, Bouches-du-Rhône, France   \n",
       "186     1991                                     Portugal   \n",
       "187     1991         Loire Valley, Indre-et-Loire, France   \n",
       "188     1991                 Montecillo, Cantabria, Spain   \n",
       "189     1991                                     Portugal   \n",
       "\n",
       "                                         Address   Latitude  Longitude  \\\n",
       "0                                       Portugal  39.682198  -7.968288   \n",
       "1                                       Portugal  39.682198  -7.968288   \n",
       "2                                       Portugal  39.682198  -7.968288   \n",
       "3                                       Portugal  39.682198  -7.968288   \n",
       "4                                       Portugal  39.682198  -7.968288   \n",
       "..                                           ...        ...        ...   \n",
       "185  Salon-de-Provence, Bouches-du-Rhône, France  43.640297   5.086390   \n",
       "186                                     Portugal  39.682198  -7.968288   \n",
       "187         Loire Valley, Indre-et-Loire, France  47.398888   0.702778   \n",
       "188                 Montecillo, Cantabria, Spain  42.774986  -3.975144   \n",
       "189                                     Portugal  39.682198  -7.968288   \n",
       "\n",
       "        TMAX_1     TMAX_2     TMAX_3  ...     TAVG_3     TAVG_4     TAVG_5  \\\n",
       "0    33.366667  43.200000  51.133333  ...  41.166667  44.566667  55.766667   \n",
       "1    36.975000  47.466667  54.350000  ...  44.050000  46.825000  57.875000   \n",
       "2    36.975000  47.466667  54.350000  ...  44.050000  46.825000  57.875000   \n",
       "3    37.066667  39.875000  47.700000  ...  39.200000  51.175000  66.425000   \n",
       "4    37.066667  39.875000  47.700000  ...  39.200000  51.175000  66.425000   \n",
       "..         ...        ...        ...  ...        ...        ...        ...   \n",
       "185  44.087500  43.911111  51.377778  ...  41.055556  49.644444  57.144444   \n",
       "186  32.622222  44.622222  51.066667  ...  40.522222  51.766667  63.700000   \n",
       "187  32.622222  44.622222  51.066667  ...  40.522222  51.766667  63.700000   \n",
       "188  32.622222  44.622222  51.066667  ...  40.522222  51.766667  63.700000   \n",
       "189  32.622222  44.622222  51.066667  ...  40.522222  51.766667  63.700000   \n",
       "\n",
       "        TAVG_6     TAVG_7     TAVG_8     TAVG_9    TAVG_10    TAVG_11  \\\n",
       "0    68.633333  72.833333  73.800000  64.900000  53.433333  39.066667   \n",
       "1    69.650000  74.025000  74.475000  66.975000  54.825000  42.400000   \n",
       "2    69.650000  74.025000  74.475000  66.975000  54.825000  42.400000   \n",
       "3    70.025000  72.275000  73.425000  63.825000  57.425000  42.350000   \n",
       "4    70.025000  72.275000  73.425000  63.825000  57.425000  42.350000   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "185  69.077778  72.777778  71.755556  65.711111  52.866667  43.655556   \n",
       "186  70.666667  74.200000  73.155556  63.644444  52.166667  35.911111   \n",
       "187  70.666667  74.200000  73.155556  63.644444  52.166667  35.911111   \n",
       "188  70.666667  74.200000  73.155556  63.644444  52.166667  35.911111   \n",
       "189  70.666667  74.200000  73.155556  63.644444  52.166667  35.911111   \n",
       "\n",
       "       TAVG_12  \n",
       "0    26.033333  \n",
       "1    29.850000  \n",
       "2    29.850000  \n",
       "3    29.350000  \n",
       "4    29.350000  \n",
       "..         ...  \n",
       "185  28.300000  \n",
       "186  32.855556  \n",
       "187  32.855556  \n",
       "188  32.855556  \n",
       "189  32.855556  \n",
       "\n",
       "[190 rows x 55 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('data/intermediate/weather_enhanced_wine_data_sample.csv')\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760fc4cc",
   "metadata": {},
   "source": [
    "From the previous test we can see that the script works to some extent. Now we add a few more logic to the script, such as making it auto-save whenever an error occurs, double checking for duplicates if the script is ran multiple times, and have capacity to have more than one API key so the whole csv file can be iterated through within a reasonable time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504fce2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid address found for Wiese & Krohn\n",
      "No valid address found for W. & J. Graham's\n",
      "No valid address found for Wiese & Krohn\n",
      "No valid address found for Wiese & Krohn\n",
      "No valid address found for W. & J. Graham's\n",
      "No valid address found for W. & J. Graham's\n",
      "No valid address found for Wiese & Krohn\n",
      "No valid address found for Wiese & Krohn\n",
      "No valid address found for Sebastiani\n",
      "No valid address found for Sebastiani\n",
      "No valid address found for Sebastiani\n",
      "No valid address found for Heidsieck & Co Monopole\n",
      "No valid address found for Heidsieck & Co Monopole\n",
      "No valid address found for Argyle\n",
      "No valid address found for Heidsieck & Co Monopole\n",
      "No valid address found for Wellington\n",
      "No valid address found for Gan Eden\n",
      "No valid address found for Argyle\n",
      "No valid address found for Gloria Ferrer\n",
      "No valid address found for Sebastiani\n",
      "No valid address found for Fortino\n",
      "No valid address found for Iron Horse\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "No valid address found for Gloria Ferrer\n",
      "No valid address found for Moet & Chandon\n",
      "No valid address found for Moet & Chandon\n",
      "No valid address found for Pacific Echo\n",
      "No valid address found for En Tirage\n",
      "No valid address found for Freemark Abbey\n",
      "No valid address found for Kirchmayr\n",
      "No valid address found for Sebastiani\n",
      "No valid address found for David Hill\n",
      "No valid address found for Iron Horse\n",
      "No valid address found for Gloria Ferrer\n",
      "No valid address found for Castello d'Albola\n",
      "No valid address found for KWV\n",
      "No valid address found for Rex Hill\n",
      "No valid address found for Moet & Chandon\n",
      "No valid address found for Hilltop Neszmely\n",
      "No valid address found for Panther Creek\n",
      "No valid address found for Moet & Chandon\n",
      "No valid address found for Schramsberg\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "No valid address found for Moet & Chandon\n",
      "No valid address found for Gloria Ferrer\n",
      "No valid address found for Iron Horse\n",
      "No valid address found for Robert Hunter\n",
      "No valid address found for Roederer Estate\n",
      "No valid address found for Korbel\n",
      "No valid address found for Bodegas Virgen del Aguila\n",
      "No valid address found for Campo Viejo\n",
      "No valid address found for Wellington\n",
      "No valid address found for Fattoria di Grignano\n",
      "No valid address found for W. & J. Graham's\n",
      "No valid address found for S. Anderson\n",
      "No valid address found for Iron Horse\n",
      "No valid address found for Laetitia\n",
      "No valid address found for Sebastiani\n",
      "No valid address found for Schramsberg\n",
      "No valid address found for Monastero di Coriano\n",
      "No valid address found for Woodbridge\n",
      "No valid address found for Gan Eden\n",
      "No valid address found for Fattoria di Grignano\n",
      "No valid address found for Schramsberg\n",
      "No valid address found for Schramsberg\n",
      "No valid address found for Schramsberg\n",
      "No valid address found for Argyle\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "No valid address found for Handley\n",
      "No valid address found for Coto de Imaz\n",
      "No valid address found for Woodbridge\n",
      "No valid address found for W. & J. Graham's\n",
      "No valid address found for Moet & Chandon\n",
      "No valid address found for Moet & Chandon\n",
      "No valid address found for Moet & Chandon\n",
      "No valid address found for Gloria Ferrer\n",
      "No valid address found for Marques de Tomares\n",
      "No valid address found for Renaissance\n",
      "No valid address found for Moet & Chandon\n",
      "No valid address found for Avignonesi\n",
      "No valid address found for Gloria Ferrer\n",
      "No valid address found for Moet & Chandon\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "No valid address found for Schramsberg\n",
      "No valid address found for Luigi Righetti\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "No valid address found for Sella & Mosca\n",
      "No valid address found for Heidsieck & Co Monopole\n",
      "No valid address found for Agrapart & Fils\n",
      "No valid address found for Jose Maria da Fonseca\n",
      "No valid address found for Iron Horse\n",
      "No valid address found for Thornton\n",
      "No valid address found for Ippolito 1845\n",
      "No valid address found for Iron Horse\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "No valid address found for DeRose\n",
      "No valid address found for Avignonesi\n",
      "No valid address found for Handley\n",
      "No valid address found for Thornton\n",
      "No valid address found for Pacific Echo\n",
      "No valid address found for Sakonnet\n",
      "No valid address found for Renwood\n",
      "No valid address found for La Rioja Alta\n",
      "No valid address found for Iron Horse\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "No valid address found for Cossart Gordon\n",
      "No valid address found for Castello Banfi\n",
      "No valid address found for Leacock's\n",
      "No valid address found for Heidsieck & Co Monopole\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "No valid address found for Cossart Gordon\n",
      "No valid address found for La Scolca\n",
      "No valid address found for Sella & Mosca\n",
      "No valid address found for Iron Horse\n",
      "No valid address found for Iron Horse\n",
      "No valid address found for Royal Tokaji\n",
      "No valid address found for Royal Tokaji\n",
      "No valid address found for Moet & Chandon\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "No valid address found for Handley\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "No valid address found for Grgich Hills\n",
      "No valid address found for Moet & Chandon\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "No valid address found for Poggio Antico\n",
      "No valid address found for Pacific Echo\n",
      "No valid address found for Andre et Mireille Tissot\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "No valid address found for Argyle\n",
      "No valid address found for Royal Tokaji\n",
      "No valid address found for Royal Tokaji\n",
      "No valid address found for Chateau St. Jean\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "No valid address found for Marques de Tomares\n",
      "No valid address found for Gloria Ferrer\n",
      "No valid address found for Chateau Frank\n",
      "No valid address found for Renaissance\n",
      "No valid address found for Miles\n",
      "No valid address found for Cantina Terlano\n",
      "No valid address found for Iron Horse\n",
      "No valid address found for Gloria Ferrer\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "No valid address found for Argyle\n",
      "No valid address found for Royal Tokaji\n",
      "No valid address found for Andre et Mireille Tissot\n",
      "No valid address found for De Sousa & Fils\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "No valid address found for Pacific Echo\n",
      "No valid address found for Royal Tokaji\n",
      "No valid address found for W. & J. Graham's\n",
      "No valid address found for Bodegas Valdemar\n",
      "No valid address found for Meridian\n",
      "No valid address found for Duck Pond\n",
      "No valid address found for Riefle\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "No valid address found for Monastero di Coriano\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "No valid address found for Renwood\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "No valid address found for Schramsberg\n",
      "No valid address found for S. Anderson\n",
      "No valid address found for Marques de Riscal\n",
      "No valid address found for Castello d'Albola\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "No valid address found for Korbel\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid address found for Broadbent\n",
      "No valid address found for Iron Horse\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "No valid address found for Mumm Cuvee Napa\n",
      "No valid address found for Vigna Piccola\n",
      "No valid address found for Agrapart & Fils\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "No valid address found for Duck Pond\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "No valid address found for Kollwentz\n",
      "No valid address found for Stellenryck\n",
      "No valid address found for Pellegrini Vineyards\n",
      "No valid address found for Domaine Carneros\n",
      "No valid address found for Glenora\n",
      "No valid address found for Bruno Giacosa\n",
      "No valid address found for Iron Horse\n",
      "No valid address found for Kunde\n",
      "No valid address found for Moet & Chandon\n",
      "No valid address found for Roederer Estate\n",
      "No valid address found for Columbia Crest\n",
      "No valid address found for Bodegas Corral\n",
      "No valid address found for Fetzer\n",
      "No valid address found for Handley\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "No valid address found for Royal Tokaji\n",
      "No valid address found for Sebastiani\n",
      "No valid address found for Newlan\n",
      "No valid address found for Chateau Souverain\n",
      "No valid address found for Schramsberg\n",
      "No valid address found for Moet & Chandon\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "No valid address found for S. Anderson\n",
      "No valid address found for Royal Tokaji\n",
      "No valid address found for Sakonnet\n",
      "No valid address found for Argyle\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "No valid address found for Moet & Chandon\n",
      "No valid address found for Castello di Selvole\n",
      "No valid address found for Beringer\n",
      "No valid address found for Argyle\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "No valid address found for Domaine Carneros\n",
      "No valid address found for Moet & Chandon\n",
      "No valid address found for Sella & Mosca\n",
      "No valid address found for Castello di Selvole\n",
      "No valid address found for Moet & Chandon\n",
      "No valid address found for Schramsberg\n",
      "No valid address found for Domaine Chandon\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "No valid address found for Thornton\n",
      "No valid address found for Beringer\n",
      "No valid address found for Covey Run\n",
      "No valid address found for Talenti\n",
      "No valid address found for Roederer Estate\n",
      "No valid address found for Pine Ridge\n",
      "No valid address found for Dry Creek Vineyard\n",
      "No valid address found for Camelot\n",
      "No valid address found for Herzog\n",
      "No valid address found for B.R. Cohn\n",
      "No valid address found for Cousino-Macul\n",
      "No valid address found for Thunder Mountain\n",
      "No valid address found for Tenuta di Sesta\n",
      "No valid address found for Spring Mountain Vineyard\n",
      "No valid address found for Topel\n",
      "No valid address found for M. Trinchero\n",
      "No valid address found for S. Anderson\n",
      "No valid address found for Chimney Rock\n",
      "No valid address found for Handley\n",
      "No valid address found for McDowell\n",
      "No valid address found for Bookwalter\n",
      "No valid address found for Lolonis\n",
      "No valid address found for Henriques & Henriques\n",
      "No valid address found for Cousino-Macul\n",
      "No valid address found for Merryvale\n",
      "No valid address found for August Briggs\n",
      "No valid address found for Karl Lawrence\n",
      "No valid address found for The Terraces\n",
      "No valid address found for Shafer\n",
      "No valid address found for Mumm Cuvee Napa\n",
      "No valid address found for Gloria Ferrer\n",
      "No valid address found for Caterina\n",
      "No valid address found for Iron Horse\n",
      "No valid address found for Cain\n",
      "No valid address found for Helmut Lang\n",
      "No valid address found for Storybook Mountain\n",
      "No valid address found for Rosenthal\n",
      "No valid address found for Iron Horse\n",
      "No valid address found for Conn Valley\n",
      "No valid address found for Kenwood\n",
      "No valid address found for Lafond\n",
      "No valid address found for Wiese & Krohn\n",
      "NOAA request timed out.\n",
      "Data appended to: data/intermediate/weather_enhanced_wine_data.csv\n",
      "No valid address found for Chateau Los Boldos\n",
      "No valid address found for Steele\n",
      "No valid address found for Fetzer\n",
      "No valid address found for Io\n",
      "No valid address found for Glen Fiona\n",
      "No valid address found for Leonetti Cellar\n",
      "No valid address found for Fetzer\n",
      "No valid address found for Villa di Bagnolo\n",
      "No valid address found for Chehalem\n",
      "No valid address found for Joullian\n",
      "No valid address found for Avignonesi\n",
      "No valid address found for Lolonis\n",
      "No valid address found for Corbett Canyon\n",
      "No valid address found for Wente\n",
      "No valid address found for Principe Corsini Fattoria Le Corti\n",
      "No valid address found for Trellis\n",
      "No valid address found for Mirassou\n",
      "No valid address found for Cardinale\n",
      "No valid address found for Wattle Creek\n",
      "No valid address found for Newlan\n",
      "No valid address found for R & B Cellars\n",
      "No valid address found for Gallo of Sonoma\n",
      "No valid address found for Wolffer\n",
      "No valid address found for Sterling\n",
      "No valid address found for Carmenet\n",
      "No valid address found for S. Anderson\n",
      "No valid address found for Podere La Cappella\n",
      "No valid address found for Pindar Vineyards\n",
      "No valid address found for Bacio Divino\n",
      "No valid address found for Treana\n",
      "No valid address found for AJB Vineyards\n",
      "No valid address found for Argyle\n",
      "No valid address found for Argyle\n",
      "No valid address found for Buttonwood Farm\n",
      "No valid address found for Terre Rouge\n",
      "No valid address found for Iron Horse\n",
      "No valid address found for Robert Mondavi\n",
      "No valid address found for Palmer\n",
      "No valid address found for Helmut Lang\n",
      "No valid address found for Cedar Mountain\n",
      "No valid address found for Tenuta La Fuga\n"
     ]
    }
   ],
   "source": [
    "# Constants for NOAA API rate limiting\n",
    "NOAA_RATE_LIMIT = 0.2  # Seconds between requests\n",
    "NOAA_DAILY_LIMIT = 10000  # Daily request limit per NOAA API token\n",
    "noaa_request_count = 0  # Initialize NOAA request count\n",
    "\n",
    "# List of NOAA API tokens\n",
    "noaa_api_tokens = [\n",
    "    'Key 1',\n",
    "    'Key 2',\n",
    "    'Key 3'\n",
    "]\n",
    "current_noaa_token_index = 0  # Current NOAA API token index\n",
    "\n",
    "# Annual limit for Bing Maps API transactions\n",
    "BING_MAPS_ANNUAL_LIMIT = 125000\n",
    "\n",
    "# List of Bing Maps API tokens and their transaction counts\n",
    "bing_maps_keys_info = [\n",
    "    {'key': 'Key 1', 'transactions': 0},\n",
    "    {'key': 'Key 2', 'transactions': 0},\n",
    "    {'key': 'Key 3', 'transactions': 0}\n",
    "]\n",
    "current_bing_key_index = 0  # Current Bing Maps API token index\n",
    "\n",
    "# Function to get the current NOAA API token\n",
    "def get_current_noaa_api_token():\n",
    "    return noaa_api_tokens[current_noaa_token_index]\n",
    "\n",
    "# Function to increment the NOAA token index\n",
    "def increment_noaa_token_index():\n",
    "    global current_noaa_token_index\n",
    "    current_noaa_token_index += 1\n",
    "    if current_noaa_token_index >= len(noaa_api_tokens):\n",
    "        print(\"All NOAA API tokens have reached their daily limit.\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Function to get the current Bing Maps API key\n",
    "def get_current_bing_maps_key():\n",
    "    return bing_maps_keys_info[current_bing_key_index]['key']\n",
    "\n",
    "# Function to increment the Bing Maps key index\n",
    "def increment_bing_key_index():\n",
    "    global current_bing_key_index\n",
    "    current_bing_key_index += 1\n",
    "    if current_bing_key_index >= len(bing_maps_keys_info):\n",
    "        print(\"All Bing Maps API tokens have reached their annual limit.\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Function to check and update Bing Maps transactions\n",
    "def check_and_update_bing_transactions():\n",
    "    global current_bing_key_index\n",
    "    if bing_maps_keys_info[current_bing_key_index]['transactions'] >= BING_MAPS_ANNUAL_LIMIT:\n",
    "        if not increment_bing_key_index():\n",
    "            return False\n",
    "    bing_maps_keys_info[current_bing_key_index]['transactions'] += 1\n",
    "    return True\n",
    "\n",
    "# Function to clean and prepare keywords\n",
    "def clean_keywords(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    # Remove text within parentheses\n",
    "    text = re.sub(r'\\(.*?\\)', '', text).strip()\n",
    "    return text\n",
    "\n",
    "# Function to create variations of the winery name\n",
    "def create_winery_variations(winery):\n",
    "    variations = [\"Wines\", \"Wine\", \"Vineyard\", \"Estate\", \"Winery\", \"Vineyards\"]\n",
    "    return [f\"{winery} {variation}\" for variation in variations] + [winery]\n",
    "\n",
    "# Function to construct search query\n",
    "def construct_query(row, winery_variations):\n",
    "    regions = [clean_keywords(row['Region 1']), clean_keywords(row['Region 2']), clean_keywords(row['Region 3'])]\n",
    "    country = clean_keywords(row['Country'])\n",
    "\n",
    "    # Construct different combinations\n",
    "    combinations = []\n",
    "    for winery_variation in winery_variations:\n",
    "        for i in range(len(regions)):\n",
    "            for j in range(i, len(regions)):\n",
    "                query_parts = [winery_variation] + regions[i:j+1] + [country]\n",
    "                combinations.append(' '.join(filter(None, query_parts)))\n",
    "\n",
    "    return combinations, regions, country\n",
    "\n",
    "# Function to calculate the bounding box\n",
    "def get_gps_bounding_box(latitude, longitude, deg_lat=1.0, deg_lon=1.0):\n",
    "    n = min(90, latitude + deg_lat)\n",
    "    s = max(-90, latitude - deg_lat)\n",
    "    e = min(180, longitude + deg_lon)\n",
    "    w = max(-180, longitude - deg_lon)\n",
    "    return n, w, s, e\n",
    "\n",
    "# Function to find weather stations by bounding box with rate limiting\n",
    "def get_stations_by_bounding_box(lat, lon):\n",
    "    global noaa_request_count\n",
    "    if noaa_request_count >= NOAA_DAILY_LIMIT:\n",
    "        if not increment_noaa_token_index():\n",
    "            return []  # All NOAA tokens exhausted\n",
    "        noaa_request_count = 0  # Reset request count for new token\n",
    "\n",
    "    api_token = get_current_noaa_api_token()\n",
    "    time.sleep(NOAA_RATE_LIMIT)\n",
    "    n, w, s, e = get_gps_bounding_box(lat, lon)\n",
    "    url = f\"https://www.ncei.noaa.gov/access/services/search/v1/data?dataset=global-summary-of-the-month&boundingBox={n},{w},{s},{e}&dataTypes=TMIN,TMAX,PRCP,TAVG&limit=10&offset=0\"\n",
    "    headers = {'token': api_token}\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        noaa_request_count += 1\n",
    "        if response.status_code == 200:\n",
    "            stations_data = response.json().get('results', [])\n",
    "            valid_stations = [station['id'].split(':')[1].split('.')[0] for station in stations_data]\n",
    "            return valid_stations\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\"NOAA request timed out.\")\n",
    "        save_progress(processed_wine_data)  # Save progress on error\n",
    "    except Exception as e:\n",
    "        print(f\"Error in NOAA request: {e}\")\n",
    "        save_progress(processed_wine_data)  # Save progress on error\n",
    "    return []\n",
    "\n",
    "# Function to get monthly climate data for a station with rate limiting\n",
    "def get_mly_climate_data_for_station(station_id, vintage_year):\n",
    "    global noaa_request_count\n",
    "    if noaa_request_count >= NOAA_DAILY_LIMIT:\n",
    "        if not increment_noaa_token_index():\n",
    "            return {}  # All NOAA tokens exhausted\n",
    "        noaa_request_count = 0  # Reset request count for new token\n",
    "\n",
    "    api_token = get_current_noaa_api_token()\n",
    "    time.sleep(NOAA_RATE_LIMIT)\n",
    "    url = f\"https://www.ncei.noaa.gov/access/services/data/v1?dataset=global-summary-of-the-month&dataTypes=TMIN,TMAX,PRCP,TAVG&stations={station_id}&startDate={vintage_year}-01-01&endDate={vintage_year}-12-31&format=json&units=standard&includeAttributes=false\"\n",
    "    headers = {'token': api_token}\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        noaa_request_count += 1\n",
    "        if response.status_code == 200:\n",
    "            monthly_data_raw = response.json()\n",
    "            monthly_data = {f\"{data_type}_{month}\": [] for data_type in ['TMIN', 'TMAX', 'PRCP', 'TAVG'] for month in range(1, 13)}\n",
    "\n",
    "            for record in monthly_data_raw:\n",
    "                month = int(record['DATE'].split('-')[1])\n",
    "                for data_type in ['TMIN', 'TMAX', 'PRCP', 'TAVG']:\n",
    "                    if record.get(data_type) is not None:\n",
    "                        monthly_data[f\"{data_type}_{month}\"].append(float(record[data_type]))\n",
    "            # Averaging the data\n",
    "            processed_data = {key: sum(values) / len(values) if values else None for key, values in monthly_data.items()}\n",
    "            return processed_data\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\"NOAA request timed out.\")\n",
    "        save_progress(processed_wine_data)  # Save progress on error\n",
    "    except Exception as e:\n",
    "        print(f\"Error in NOAA request: {e}\")\n",
    "        save_progress(processed_wine_data)  # Save progress on error\n",
    "    return {}\n",
    "\n",
    "# Function to search using Bing Maps API\n",
    "def search_address(query):\n",
    "    if not check_and_update_bing_transactions():\n",
    "        return None  # All Bing Maps keys exhausted or reached limit\n",
    "\n",
    "    key = get_current_bing_maps_key()\n",
    "    url = f\"http://dev.virtualearth.net/REST/v1/Locations?query={query}&key={key}\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        elif response.status_code == 401:  # Assuming 401 indicates a key limit\n",
    "            if increment_bing_key_index():\n",
    "                return search_address(query)  # Retry with the next key\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "        save_progress(processed_wine_data)  # Save progress on error\n",
    "    return None\n",
    "\n",
    "# Additional helper functions (e.g., is_country_match, is_region_country_match, extract_address_info)\n",
    "def is_country_match(country, address):\n",
    "    return country.lower() in address.lower()\n",
    "\n",
    "def is_region_country_match(regions, country, address):\n",
    "    address_lower = address.lower()\n",
    "    return any(region.lower() in address_lower for region in regions if region) and country.lower() in address_lower\n",
    "\n",
    "def extract_address_info(result):\n",
    "    if result and 'resourceSets' in result and result['resourceSets']:\n",
    "        resources = result['resourceSets'][0]['resources']\n",
    "        if resources:\n",
    "            location_name = resources[0].get('name', '')\n",
    "            address = resources[0]['address'].get('formattedAddress', '')\n",
    "            coordinates = resources[0]['point']['coordinates'] if 'point' in resources[0] else None\n",
    "            return location_name, address, coordinates\n",
    "    return None, None, None\n",
    "\n",
    "# Function to append data to CSV\n",
    "def append_to_csv(dataframe, filepath):\n",
    "    dataframe.to_csv(filepath, mode='a', header=not os.path.exists(filepath), index=False)\n",
    "    print(\"Data appended to:\", filepath)\n",
    "\n",
    "# Function to save progress whenever an error occurs\n",
    "def save_progress(processed_data, filepath='data/intermediate/weather_enhanced_wine_data.csv'):\n",
    "    current_data_df = pd.DataFrame(processed_data)\n",
    "    append_to_csv(current_data_df, filepath)\n",
    "\n",
    "# Function to process each wine entry with error handling\n",
    "def process_wine_entry(row):\n",
    "    try:\n",
    "        winery = clean_keywords(row['Winery'])\n",
    "        winery_variations = create_winery_variations(winery)\n",
    "        queries, regions, country = construct_query(row, winery_variations)\n",
    "        for query in queries:\n",
    "            result = search_address(query)\n",
    "            location_name, address, coordinates = extract_address_info(result)\n",
    "            if location_name and address and coordinates:\n",
    "                if is_correct_business_match(winery_variations, location_name, address, country) or is_region_country_match(regions, country, address):\n",
    "                    lat, lon = coordinates\n",
    "                    station_results = get_stations_by_bounding_box(lat, lon)\n",
    "                    if station_results:\n",
    "                        aggregated_weather_data = defaultdict(list)\n",
    "                        for station_id in station_results:\n",
    "                            station_weather_data = get_mly_climate_data_for_station(station_id, row['Vintage'])\n",
    "                            for key, value in station_weather_data.items():\n",
    "                                if value is not None:  # Only append if value is not None\n",
    "                                    aggregated_weather_data[key].append(value)\n",
    "                        averaged_weather_data = {k: sum(v)/len(v) for k, v in aggregated_weather_data.items() if v}\n",
    "                        return {\n",
    "                            \"Winery\": row['Winery'],\n",
    "                            \"Wine Name\": row['Wine Name'],\n",
    "                            \"Vintage\": row['Vintage'],\n",
    "                            \"Location Name\": location_name,\n",
    "                            \"Address\": address,\n",
    "                            \"Latitude\": lat,\n",
    "                            \"Longitude\": lon,\n",
    "                            **averaged_weather_data\n",
    "                        }\n",
    "        print(f\"No valid address found for {row['Winery']}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {row['Winery']}: {e}\")\n",
    "        save_progress(processed_wine_data)  # Save progress on error\n",
    "        raise  # Optionally re-raise the exception\n",
    "\n",
    "# Main script execution\n",
    "intermediate_file_path = 'data/intermediate/weather_enhanced_wine_data.csv'\n",
    "\n",
    "# Read existing data if available\n",
    "if os.path.exists(intermediate_file_path):\n",
    "    processed_wine_data_df = pd.read_csv(intermediate_file_path)\n",
    "else:\n",
    "    processed_wine_data_df = pd.DataFrame()\n",
    "\n",
    "# Read the main wine data\n",
    "wine_data = pd.read_csv('data/clean/cleaned_combined_wine_data.csv')\n",
    "\n",
    "# Filter out already processed wines\n",
    "processed_wine_names = set(processed_wine_data_df['Wine Name'])\n",
    "wine_data = wine_data[~wine_data['Wine Name'].isin(processed_wine_names)]\n",
    "\n",
    "# Process each wine entry\n",
    "processed_wine_data = []\n",
    "for _, row in wine_data.iterrows():\n",
    "    processed_data = process_wine_entry(row)\n",
    "    if processed_data:\n",
    "        processed_wine_data.append(processed_data)\n",
    "\n",
    "# Append new data to the intermediate file\n",
    "new_processed_data_df = pd.DataFrame(processed_wine_data)\n",
    "append_to_csv(new_processed_data_df, intermediate_file_path)\n",
    "\n",
    "# Display the results\n",
    "new_processed_data_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
